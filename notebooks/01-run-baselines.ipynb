{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics._scorer import _BaseScorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../\"\n",
    "DATASET = os.path.join(ROOT, \"data/br-pt-narrative-essays.csv\")\n",
    "SCORING = {\n",
    "    \"acc\": make_scorer(accuracy_score),\n",
    "    \"macro_prec\": make_scorer(precision_score, average=\"macro\"),\n",
    "    \"weighted_prec\": make_scorer(precision_score, average=\"weighted\"),\n",
    "    \"macro_recall\": make_scorer(recall_score, average=\"macro\"),\n",
    "    \"weighted_recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "    \"macro_f1\": make_scorer(f1_score, average=\"macro\"),\n",
    "    \"weighted_f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "    \"kappa\": make_scorer(cohen_kappa_score)\n",
    "}\n",
    "CV = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='bert-base-uncased', max_length=128):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Tokenize and encode the text\n",
    "        inputs = self.tokenizer(X, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_length)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        # Get the CLS token embedding for classification tasks\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "def scores_to_df(scores: tuple[tuple[str, str, float]]) -> pd.DataFrame:\n",
    "    \"\"\"Transform the scores dictionary into a dataframe object.\"\"\"\n",
    "    data = []\n",
    "    for score in scores:\n",
    "        data.append(\n",
    "            {\n",
    "                \"algo\": score[\"algo\"],\n",
    "                \"encoder\": score[\"encoder\"],\n",
    "                \"acc\": np.mean(score[\"test_acc\"]),\n",
    "                \"macro_prec\": np.mean(score[\"test_macro_prec\"]),\n",
    "                \"weighted_prec\": np.mean(score[\"test_weighted_prec\"]),\n",
    "                \"macro_recall\": np.mean(score[\"test_macro_recall\"]),\n",
    "                \"weighted_recall\": np.mean(score[\"test_weighted_recall\"]),\n",
    "                \"macro_f1\": np.mean(score[\"test_macro_f1\"]),\n",
    "                \"weighted_f1\": np.mean(score[\"test_weighted_f1\"]),\n",
    "                \"kappa\": np.mean(score[\"test_kappa\"]),\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove unwanted tokens from the text.\"\"\"\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def _create_tfidf_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", TfidfVectorizer()),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_bert_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_sklearn_experiments(\n",
    "    clfs: list[BaseEstimator],\n",
    "    df: pd.DataFrame,\n",
    "    scoring: dict[str, _BaseScorer],\n",
    "    cv: int,\n",
    "    preprocessors: list[Any],\n",
    "    feature_column: str,\n",
    "    target_column: str,\n",
    "    n_jobs: int = 1,\n",
    "):\n",
    "    \"\"\"Run Scikit-Learn based experiments.\"\"\"\n",
    "\n",
    "    ALGO_NAME_DICT = {\n",
    "        ExtraTreesClassifier: \"Extra Trees\",\n",
    "        DecisionTreeClassifier: \"Decision Tree\",\n",
    "        SVC: \"Support Vector\",\n",
    "        RandomForestClassifier: \"Random Forest\",\n",
    "    }\n",
    "\n",
    "    ENCODER_NAME_DICT = {\n",
    "        TfidfVectorizer: \"TF-IDF\",\n",
    "    }\n",
    "\n",
    "    def _run_sklearn_cv(\n",
    "        clf: BaseEstimator,\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.DataFrame,\n",
    "        scoring: dict[str, _BaseScorer],\n",
    "        cv: int,\n",
    "    ):\n",
    "        \"\"\"Run cross-validation on a Scikit-Learn estimator.\"\"\"\n",
    "\n",
    "        assert issubclass(type(clf), BaseEstimator) is True\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            clf,\n",
    "            X,\n",
    "            y,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        cv_results[\"algo\"] = ALGO_NAME_DICT[type(clf.named_steps[\"clf\"])]\n",
    "        cv_results[\"encoder\"] = ENCODER_NAME_DICT[type(clf.named_steps[\"encoder\"])]\n",
    "        return cv_results\n",
    "\n",
    "    cv_results_list = []\n",
    "\n",
    "    # Apply preprocessors\n",
    "    for preprocessor in preprocessors:\n",
    "        df[feature_column] = df[feature_column].apply(\n",
    "            lambda feature: preprocessor(feature)\n",
    "        )\n",
    "\n",
    "    for clf in clfs:\n",
    "        # Create pipelines\n",
    "        tfidf_pipeline = _create_tfidf_pipeline(clf)\n",
    "        # bert_pipeline = _create_bert_pipeline(clf)\n",
    "\n",
    "        # Run CV using the pipelines\n",
    "        tfidf_cv_results_list = _run_sklearn_cv(\n",
    "            tfidf_pipeline,\n",
    "            df[feature_column],\n",
    "            df[target_column],\n",
    "            scoring,\n",
    "            cv,\n",
    "        )\n",
    "        # bert_cv_results_list = _run_sklearn_cv(bert_pipeline, X, y, scoring, cv, random_state)\n",
    "\n",
    "        # Join results\n",
    "        # cv_results_list = tfidf_cv_results_list + bert_cv_results_list\n",
    "        cv_results_list.append(tfidf_cv_results_list)\n",
    "\n",
    "    return cv_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>motivating_situation</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_path</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>thematic_coherence</th>\n",
       "      <th>formal_register</th>\n",
       "      <th>text_typology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( O chorrinho nino                  )\\n-\\nEu e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv9Hx6KGe/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.As meninas do potes de Tintas [T]\\nUma vez eu...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5JtrLWUO/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 uma menina encontrou varios potes de tinta  ...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDeEANF2IC/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011 [T] A menina da (artes). \\n\\nDePois que e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSvqcNloNM/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/03/2022\\n[T] A cobra felena\\nem uma tarde m...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe9z0n6oY/...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ( O chorrinho nino                  )\\n-\\nEu e...   \n",
       "1  .As meninas do potes de Tintas [T]\\nUma vez eu...   \n",
       "2  1 uma menina encontrou varios potes de tinta  ...   \n",
       "3  2011 [T] A menina da (artes). \\n\\nDePois que e...   \n",
       "4  28/03/2022\\n[T] A cobra felena\\nem uma tarde m...   \n",
       "\n",
       "                                motivating_situation  \\\n",
       "0  Eu encontrei em cima do armário alguns potes c...   \n",
       "1  Eu encontrei em cima do armário alguns potes c...   \n",
       "2  Eu encontrei em cima do armário alguns potes c...   \n",
       "3  Eu encontrei em cima do armário alguns potes c...   \n",
       "4  Eu encontrei em cima do armário alguns potes c...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "1  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "2  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "3  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "4  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "\n",
       "                                          image_path  cohesion  \\\n",
       "0  MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv9Hx6KGe/...         3   \n",
       "1  MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5JtrLWUO/...         3   \n",
       "2  MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDeEANF2IC/...         3   \n",
       "3  MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSvqcNloNM/...         3   \n",
       "4  MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe9z0n6oY/...         4   \n",
       "\n",
       "   thematic_coherence  formal_register  text_typology  \n",
       "0                   3                3              4  \n",
       "1                   3                3              4  \n",
       "2                   3                3              4  \n",
       "3                   3                3              4  \n",
       "4                   1                4              4  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreesClassifier()\n",
    "]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "    cv_results = run_sklearn_experiments(clfs, df, scoring=SCORING, cv=CV, preprocessors=[clean_text], feature_column=\"text\", target_column=\"cohesion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>encoder</th>\n",
       "      <th>acc</th>\n",
       "      <th>macro_prec</th>\n",
       "      <th>weighted_prec</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.681825</td>\n",
       "      <td>0.259292</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>0.206309</td>\n",
       "      <td>0.681825</td>\n",
       "      <td>0.175538</td>\n",
       "      <td>0.560300</td>\n",
       "      <td>0.020110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.666670</td>\n",
       "      <td>0.299165</td>\n",
       "      <td>0.530862</td>\n",
       "      <td>0.228474</td>\n",
       "      <td>0.666670</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.031691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.557256</td>\n",
       "      <td>0.296601</td>\n",
       "      <td>0.543236</td>\n",
       "      <td>0.276714</td>\n",
       "      <td>0.557256</td>\n",
       "      <td>0.281307</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.079544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.651502</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>0.518574</td>\n",
       "      <td>0.225143</td>\n",
       "      <td>0.651502</td>\n",
       "      <td>0.212490</td>\n",
       "      <td>0.559056</td>\n",
       "      <td>0.021207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algo encoder       acc  macro_prec  weighted_prec  macro_recall  \\\n",
       "0  Support Vector  TF-IDF  0.681825    0.259292       0.544278      0.206309   \n",
       "1   Random Forest  TF-IDF  0.666670    0.299165       0.530862      0.228474   \n",
       "2   Decision Tree  TF-IDF  0.557256    0.296601       0.543236      0.276714   \n",
       "3     Extra Trees  TF-IDF  0.651502    0.250197       0.518574      0.225143   \n",
       "\n",
       "   weighted_recall  macro_f1  weighted_f1     kappa  \n",
       "0         0.681825  0.175538     0.560300  0.020110  \n",
       "1         0.666670  0.217940     0.565789  0.031691  \n",
       "2         0.557256  0.281307     0.548780  0.079544  \n",
       "3         0.651502  0.212490     0.559056  0.021207  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = scores_to_df(cv_results)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost_experiments(clf, X: pd.DataFrame, y: pd.DataFrame, random_state: int = 42):\n",
    "    \"\"\"Run XGBoost based experiments.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catboost_experiments(clf, X: pd.DataFrame, y: pd.DataFrame, random_state: int = 42):\n",
    "    \"\"\"Run CatBoost based experiments.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
