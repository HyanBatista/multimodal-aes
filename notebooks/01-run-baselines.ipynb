{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "import torch\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics._scorer import _BaseScorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"../data/\"\n",
    "DATASET = os.path.join(ROOT, \"br-pt-narrative-essays.csv\")\n",
    "SCORING = {\n",
    "    \"acc\": make_scorer(accuracy_score),\n",
    "    \"macro_prec\": make_scorer(precision_score, average=\"macro\"),\n",
    "    \"weighted_prec\": make_scorer(precision_score, average=\"weighted\"),\n",
    "    \"macro_recall\": make_scorer(recall_score, average=\"macro\"),\n",
    "    \"weighted_recall\": make_scorer(recall_score, average=\"weighted\"),\n",
    "    \"macro_f1\": make_scorer(f1_score, average=\"macro\"),\n",
    "    \"weighted_f1\": make_scorer(f1_score, average=\"weighted\"),\n",
    "    \"kappa\": make_scorer(cohen_kappa_score)\n",
    "}\n",
    "CV = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"neuralmind/bert-base-portuguese-cased\",\n",
    "        max_length=128,\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Tokenize and encode the text, and get CLS token embedding for classification tasks\"\"\"\n",
    "\n",
    "        X = list(X)\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            raise ValueError(\"Not a list of strings\")\n",
    "        elif not all(isinstance(x, str) for x in X):\n",
    "            raise ValueError(\"Not all instances are strings.\")\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            X,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "class LBPEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"LBP encoder for image data.\"\"\"\n",
    "\n",
    "    def __init__(self, radius: int = 1, sampling_pixels: int = 106):\n",
    "        self.radius = radius\n",
    "        self.sampling_pixels = sampling_pixels\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Extract the LBP from the images batch.\"\"\"\n",
    "        logger.debug(\"Encoding images...\")\n",
    "        X = list(X)\n",
    "        logger.debug(\"Converting...\")\n",
    "        cvt_imgs = [self._cvt(img) for img in X]\n",
    "        logger.debug(\"Running LBP algorithm...\")\n",
    "        imgs_lbps = [self._get_lbp(img) for img in cvt_imgs]\n",
    "        logger.debug(\"Getting the histograms...\")\n",
    "        imgs_hists = [self._get_hist(img_lbp) for img_lbp in imgs_lbps]\n",
    "        logger.debug(\"Extracting LBP features from histograms...\")\n",
    "        features = self._get_features(imgs_hists)\n",
    "        logger.debug(\"Finished with encoding images\")\n",
    "\n",
    "        return features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _cvt(self, img):\n",
    "        if len(img.shape) > 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        i_min = np.min(img)\n",
    "        i_max = np.max(img)\n",
    "        if i_max - i_min != 0:\n",
    "            img = (img - i_min) / (i_max - i_min)\n",
    "\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _get_lbp(self, img):\n",
    "        lbp = ski.feature.local_binary_pattern(\n",
    "            img, self.sampling_pixels, self.radius, method=\"uniform\"\n",
    "        )\n",
    "        return (img, lbp)\n",
    "\n",
    "    def _get_hist(self, img_lbp):\n",
    "        img, lbp = img_lbp\n",
    "        hist, _ = np.histogram(\n",
    "            lbp.ravel(),\n",
    "            bins=np.arange(0, self.sampling_pixels + 3),\n",
    "            range=(0, self.sampling_pixels + 2),\n",
    "        )\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= hist.sum() + 1e-6\n",
    "        return img, hist\n",
    "    \n",
    "    def _get_features(self, imgs_hists):\n",
    "        hists = [img_hist[1] for img_hist in imgs_hists]\n",
    "        features = []\n",
    "        for h in hists:\n",
    "            features.extend(h)\n",
    "        return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tfidf_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", TfidfVectorizer()),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_lbp_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", LBPEncoder()),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_bert_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline([(\"encoder\", BERTEncoder()), (\"clf\", clf)])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_to_df(scores: tuple[tuple[str, str, float]]) -> pd.DataFrame:\n",
    "    \"\"\"Transform the scores dictionary into a dataframe object.\"\"\"\n",
    "    data = []\n",
    "    for score in scores:\n",
    "        data.append(\n",
    "            {\n",
    "                \"algo\": score[\"algo\"],\n",
    "                \"encoder\": score[\"encoder\"],\n",
    "                \"acc\": np.mean(score[\"test_acc\"]),\n",
    "                \"macro_prec\": np.mean(score[\"test_macro_prec\"]),\n",
    "                \"weighted_prec\": np.mean(score[\"test_weighted_prec\"]),\n",
    "                \"macro_recall\": np.mean(score[\"test_macro_recall\"]),\n",
    "                \"weighted_recall\": np.mean(score[\"test_weighted_recall\"]),\n",
    "                \"macro_f1\": np.mean(score[\"test_macro_f1\"]),\n",
    "                \"weighted_f1\": np.mean(score[\"test_weighted_f1\"]),\n",
    "                \"kappa\": np.mean(score[\"test_kappa\"]),\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove unwanted tokens from the text.\"\"\"\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def transform_image(image):\n",
    "    resized_image = cv2.resize(image, (100, 100))\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "def run_experiments(\n",
    "    clfs: list[BaseEstimator],\n",
    "    df: pd.DataFrame,\n",
    "    scoring: dict[str, _BaseScorer],\n",
    "    cv: int,\n",
    "    preprocessors: list[Any],\n",
    "    text_feature_column: str,\n",
    "    image_feature_column: str,\n",
    "    target_column: str,\n",
    "    n_jobs: int = 1,\n",
    "):\n",
    "    \"\"\"Run Scikit-Learn based experiments.\"\"\"\n",
    "\n",
    "    ALGO_NAME_DICT = {\n",
    "        ExtraTreesClassifier: \"Extra Trees\",\n",
    "        DecisionTreeClassifier: \"Decision Tree\",\n",
    "        SVC: \"Support Vector\",\n",
    "        RandomForestClassifier: \"Random Forest\",\n",
    "        CatBoostClassifier: \"CatBoost\",\n",
    "        XGBClassifier: \"XGBoost\",\n",
    "        MLPClassifier: \"MLP\"\n",
    "        \n",
    "    }\n",
    "\n",
    "    ENCODER_NAME_DICT = {\n",
    "        TfidfVectorizer: \"TF-IDF\",\n",
    "        BERTEncoder: \"BERT\",\n",
    "        LBPEncoder: \"LBP\"\n",
    "    }\n",
    "\n",
    "    def _run_sklearn_cv(\n",
    "        clf: BaseEstimator,\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.DataFrame,\n",
    "        scoring: dict[str, _BaseScorer],\n",
    "        cv: int,\n",
    "    ):\n",
    "        \"\"\"Run cross-validation on a Scikit-Learn estimator.\"\"\"\n",
    "\n",
    "        assert issubclass(type(clf), BaseEstimator) is True\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            clf,\n",
    "            X,\n",
    "            y,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "        cv_results[\"algo\"] = ALGO_NAME_DICT[type(clf.named_steps[\"clf\"])]\n",
    "        cv_results[\"encoder\"] = ENCODER_NAME_DICT[type(clf.named_steps[\"encoder\"])]\n",
    "        return cv_results\n",
    "\n",
    "    cv_results_list = []\n",
    "\n",
    "    # Apply preprocessors\n",
    "    for preprocessor in preprocessors[\"image\"]:\n",
    "        df[image_feature_column] = df[image_feature_column].apply(\n",
    "            lambda feature: preprocessor(cv2.imread(feature))\n",
    "        )\n",
    "\n",
    "    for preprocessor in preprocessors[\"text\"]:\n",
    "        df[text_feature_column] = df[text_feature_column].apply(\n",
    "            lambda feature: preprocessor(feature)\n",
    "        )\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[target_column] = label_encoder.fit_transform(df[target_column])\n",
    "\n",
    "    for i, clf in enumerate(tqdm(clfs, desc=\"Classifiers\")):\n",
    "        clf_name = ALGO_NAME_DICT[type(clf)]\n",
    "        logger.debug(f\"#{i + 1} classifier: {clf_name}\")\n",
    "\n",
    "        # Create pipelines\n",
    "        tfidf_pipeline = _create_tfidf_pipeline(clf)\n",
    "        bert_pipeline = _create_bert_pipeline(clf)\n",
    "        lbp_pipeline = _create_lbp_pipeline(clf)\n",
    "\n",
    "        # Run CV using the pipelines\n",
    "        logger.debug(f\"Running TF-IDF pipeline #{i + 1}\")\n",
    "        tfidf_cv_results = _run_sklearn_cv(\n",
    "            tfidf_pipeline,\n",
    "            df[text_feature_column],\n",
    "            df[target_column],\n",
    "            scoring,\n",
    "            cv,\n",
    "        )\n",
    "        logger.debug(f\"Ending TF-IDF pipeline #{i + 1}\")\n",
    "\n",
    "        bert_cv_results = _run_sklearn_cv(\n",
    "            bert_pipeline,\n",
    "            df[text_feature_column],\n",
    "            df[target_column],\n",
    "            scoring,\n",
    "            cv,\n",
    "        )\n",
    "\n",
    "        logger.debug(f\"Running LBP pipeline #{i + 1}\")\n",
    "        lbp_cv_results = _run_sklearn_cv(\n",
    "            lbp_pipeline,\n",
    "            df[image_feature_column],\n",
    "            df[target_column],\n",
    "            scoring,\n",
    "            cv,\n",
    "        )\n",
    "        logger.debug(f\"Ending LBP pipeline #{i + 1}\")\n",
    "\n",
    "        # Append results\n",
    "        cv_results_list.append(tfidf_cv_results)\n",
    "        cv_results_list.append(bert_cv_results)\n",
    "        cv_results_list.append(lbp_cv_results)\n",
    "\n",
    "    return cv_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>motivating_situation</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_path</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>thematic_coherence</th>\n",
       "      <th>formal_register</th>\n",
       "      <th>text_typology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( O chorrinho nino                  )\\n-\\nEu e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv9Hx6KGe/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.As meninas do potes de Tintas [T]\\nUma vez eu...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5JtrLWUO/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 uma menina encontrou varios potes de tinta  ...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDeEANF2IC/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011 [T] A menina da (artes). \\n\\nDePois que e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSvqcNloNM/...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/03/2022\\n[T] A cobra felena\\nem uma tarde m...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe9z0n6oY/...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ( O chorrinho nino                  )\\n-\\nEu e...   \n",
       "1  .As meninas do potes de Tintas [T]\\nUma vez eu...   \n",
       "2  1 uma menina encontrou varios potes de tinta  ...   \n",
       "3  2011 [T] A menina da (artes). \\n\\nDePois que e...   \n",
       "4  28/03/2022\\n[T] A cobra felena\\nem uma tarde m...   \n",
       "\n",
       "                                motivating_situation  \\\n",
       "0  Eu encontrei em cima do armário alguns potes c...   \n",
       "1  Eu encontrei em cima do armário alguns potes c...   \n",
       "2  Eu encontrei em cima do armário alguns potes c...   \n",
       "3  Eu encontrei em cima do armário alguns potes c...   \n",
       "4  Eu encontrei em cima do armário alguns potes c...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "1  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "2  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "3  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "4  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "\n",
       "                                          image_path  cohesion  \\\n",
       "0  MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv9Hx6KGe/...         3   \n",
       "1  MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5JtrLWUO/...         3   \n",
       "2  MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDeEANF2IC/...         3   \n",
       "3  MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSvqcNloNM/...         3   \n",
       "4  MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe9z0n6oY/...         4   \n",
       "\n",
       "   thematic_coherence  formal_register  text_typology  \n",
       "0                   3                3              4  \n",
       "1                   3                3              4  \n",
       "2                   3                3              4  \n",
       "3                   3                3              4  \n",
       "4                   1                4              4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>motivating_situation</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_path</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>thematic_coherence</th>\n",
       "      <th>formal_register</th>\n",
       "      <th>text_typology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( O chorrinho nino                  )\\n-\\nEu e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.As meninas do potes de Tintas [T]\\nUma vez eu...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 uma menina encontrou varios potes de tinta  ...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDe...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011 [T] A menina da (artes). \\n\\nDePois que e...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSv...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/03/2022\\n[T] A cobra felena\\nem uma tarde m...</td>\n",
       "      <td>Eu encontrei em cima do armário alguns potes c...</td>\n",
       "      <td>https://storage.googleapis.com/ciclos-10698-bu...</td>\n",
       "      <td>../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ( O chorrinho nino                  )\\n-\\nEu e...   \n",
       "1  .As meninas do potes de Tintas [T]\\nUma vez eu...   \n",
       "2  1 uma menina encontrou varios potes de tinta  ...   \n",
       "3  2011 [T] A menina da (artes). \\n\\nDePois que e...   \n",
       "4  28/03/2022\\n[T] A cobra felena\\nem uma tarde m...   \n",
       "\n",
       "                                motivating_situation  \\\n",
       "0  Eu encontrei em cima do armário alguns potes c...   \n",
       "1  Eu encontrei em cima do armário alguns potes c...   \n",
       "2  Eu encontrei em cima do armário alguns potes c...   \n",
       "3  Eu encontrei em cima do armário alguns potes c...   \n",
       "4  Eu encontrei em cima do armário alguns potes c...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "1  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "2  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "3  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "4  https://storage.googleapis.com/ciclos-10698-bu...   \n",
       "\n",
       "                                          image_path  cohesion  \\\n",
       "0  ../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/iet1QFw2ARNkv...         3   \n",
       "1  ../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/F80gTOBoh2Lk5...         3   \n",
       "2  ../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/HjnamZPzaZcDe...         3   \n",
       "3  ../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/r3DUtFJn9twSv...         3   \n",
       "4  ../data/MEC/Rc7dMxTP7ZdLNEvmF0jo/tKZIn59KtOcbe...         4   \n",
       "\n",
       "   thematic_coherence  formal_register  text_typology  \n",
       "0                   3                3              4  \n",
       "1                   3                3              4  \n",
       "2                   3                3              4  \n",
       "3                   3                3              4  \n",
       "4                   1                4              4  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image_path\"] = df[\"image_path\"].apply(lambda image_path: os.path.join(ROOT, image_path))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1188 entries, 0 to 1187\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   text                  1188 non-null   object\n",
      " 1   motivating_situation  1188 non-null   object\n",
      " 2   image_url             1188 non-null   object\n",
      " 3   image_path            1188 non-null   object\n",
      " 4   cohesion              1188 non-null   int64 \n",
      " 5   thematic_coherence    1188 non-null   int64 \n",
      " 6   formal_register       1188 non-null   int64 \n",
      " 7   text_typology         1188 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_truncated_images(df, column_name):\n",
    "    \"\"\"\n",
    "    Remove rows with truncated or corrupted images from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing image file paths.\n",
    "    column_name (str): Column name containing image file paths.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with rows containing truncated or corrupted images removed.\n",
    "    \"\"\"\n",
    "    # Function to check if an image is valid\n",
    "    def is_valid_image(image_path):\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            check_chars = image_file.read()[-2:]\n",
    "        if check_chars != b'\\xff\\xd9':\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    # Apply the function to the DataFrame and filter out invalid images\n",
    "    valid_image_paths = df[column_name].apply(is_valid_image)\n",
    "    filtered_df = df[valid_image_paths].reset_index(drop=True)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "df = remove_truncated_images(df, \"image_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1163 entries, 0 to 1162\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   text                  1163 non-null   object\n",
      " 1   motivating_situation  1163 non-null   object\n",
      " 2   image_url             1163 non-null   object\n",
      " 3   image_path            1163 non-null   object\n",
      " 4   cohesion              1163 non-null   int64 \n",
      " 5   thematic_coherence    1163 non-null   int64 \n",
      " 6   formal_register       1163 non-null   int64 \n",
      " 7   text_typology         1163 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 72.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"image\"] = df[\"image_path\"].progress_apply(lambda image_path: transform_image(cv2.imread(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp_encoder = LBPEncoder()\n",
    "# features = lbp_encoder.fit_transform(df[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660b426fee804b32b963c4e1cc1d5fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "1 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "1 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "1 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/hyanbatista42/miniconda3/envs/multimodal-aes/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [0 2 3 4]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "clfs = [\n",
    "    SVC(random_state=SEED),\n",
    "    RandomForestClassifier(random_state=SEED),\n",
    "    DecisionTreeClassifier(random_state=SEED),\n",
    "    ExtraTreesClassifier(random_state=SEED),\n",
    "    XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "    ),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=SEED),\n",
    "]\n",
    "\n",
    "test_df = df.sample(n=100)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "    warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "    warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "    preprocessors = {\"text\": [clean_text], \"image\": [transform_image]}\n",
    "    cv_results = run_experiments(\n",
    "        clfs,\n",
    "        test_df,\n",
    "        scoring=SCORING,\n",
    "        cv=CV,\n",
    "        preprocessors=preprocessors,\n",
    "        text_feature_column=\"text\",\n",
    "        image_feature_column=\"image_path\",\n",
    "        target_column=\"text_typology\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>encoder</th>\n",
       "      <th>acc</th>\n",
       "      <th>macro_prec</th>\n",
       "      <th>weighted_prec</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.177984</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.177984</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.177984</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.396079</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.240161</td>\n",
       "      <td>0.470538</td>\n",
       "      <td>0.070588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.186160</td>\n",
       "      <td>0.396740</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.203393</td>\n",
       "      <td>0.461057</td>\n",
       "      <td>0.028393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.238535</td>\n",
       "      <td>0.416617</td>\n",
       "      <td>0.265076</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.241085</td>\n",
       "      <td>0.458170</td>\n",
       "      <td>0.031267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.269860</td>\n",
       "      <td>0.415283</td>\n",
       "      <td>0.288788</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.273715</td>\n",
       "      <td>0.414790</td>\n",
       "      <td>0.016279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.251042</td>\n",
       "      <td>0.480762</td>\n",
       "      <td>0.288697</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>0.480115</td>\n",
       "      <td>0.130162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.250103</td>\n",
       "      <td>0.450608</td>\n",
       "      <td>0.253682</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.233978</td>\n",
       "      <td>0.427401</td>\n",
       "      <td>0.032680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.234342</td>\n",
       "      <td>0.396079</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.240161</td>\n",
       "      <td>0.470538</td>\n",
       "      <td>0.070588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.276170</td>\n",
       "      <td>0.470696</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.251653</td>\n",
       "      <td>0.502514</td>\n",
       "      <td>0.103766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.237804</td>\n",
       "      <td>0.425727</td>\n",
       "      <td>0.265121</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.240318</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.054827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>LBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.237368</td>\n",
       "      <td>0.403053</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.242554</td>\n",
       "      <td>0.476043</td>\n",
       "      <td>0.085423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLP</td>\n",
       "      <td>BERT</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.401877</td>\n",
       "      <td>0.528005</td>\n",
       "      <td>0.383864</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.374447</td>\n",
       "      <td>0.531258</td>\n",
       "      <td>0.177329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLP</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.177984</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              algo encoder   acc  macro_prec  weighted_prec  macro_recall  \\\n",
       "0   Support Vector  TF-IDF  0.59    0.141500       0.348500      0.240000   \n",
       "1   Support Vector    BERT  0.59    0.141500       0.348500      0.240000   \n",
       "2   Support Vector     LBP  0.59    0.141500       0.348500      0.240000   \n",
       "3    Random Forest  TF-IDF  0.61    0.234342       0.396079      0.285000   \n",
       "4    Random Forest    BERT  0.58    0.186160       0.396740      0.247500   \n",
       "5    Random Forest     LBP  0.53    0.238535       0.416617      0.265076   \n",
       "6    Decision Tree  TF-IDF  0.43    0.269860       0.415283      0.288788   \n",
       "7    Decision Tree    BERT  0.49    0.251042       0.480762      0.288697   \n",
       "8    Decision Tree     LBP  0.44    0.250103       0.450608      0.253682   \n",
       "9      Extra Trees  TF-IDF  0.61    0.234342       0.396079      0.285000   \n",
       "10     Extra Trees    BERT  0.62    0.276170       0.470696      0.285833   \n",
       "11     Extra Trees     LBP  0.54    0.237804       0.425727      0.265121   \n",
       "12         XGBoost  TF-IDF   NaN         NaN            NaN           NaN   \n",
       "13         XGBoost    BERT   NaN         NaN            NaN           NaN   \n",
       "14         XGBoost     LBP   NaN         NaN            NaN           NaN   \n",
       "15             MLP  TF-IDF  0.61    0.237368       0.403053      0.285000   \n",
       "16             MLP    BERT  0.57    0.401877       0.528005      0.383864   \n",
       "17             MLP     LBP  0.59    0.141500       0.348500      0.240000   \n",
       "\n",
       "    weighted_recall  macro_f1  weighted_f1     kappa  \n",
       "0              0.59  0.177984     0.438065  0.000000  \n",
       "1              0.59  0.177984     0.438065  0.000000  \n",
       "2              0.59  0.177984     0.438065  0.000000  \n",
       "3              0.61  0.240161     0.470538  0.070588  \n",
       "4              0.58  0.203393     0.461057  0.028393  \n",
       "5              0.53  0.241085     0.458170  0.031267  \n",
       "6              0.43  0.273715     0.414790  0.016279  \n",
       "7              0.49  0.262520     0.480115  0.130162  \n",
       "8              0.44  0.233978     0.427401  0.032680  \n",
       "9              0.61  0.240161     0.470538  0.070588  \n",
       "10             0.62  0.251653     0.502514  0.103766  \n",
       "11             0.54  0.240318     0.466100  0.054827  \n",
       "12              NaN       NaN          NaN       NaN  \n",
       "13              NaN       NaN          NaN       NaN  \n",
       "14              NaN       NaN          NaN       NaN  \n",
       "15             0.61  0.242554     0.476043  0.085423  \n",
       "16             0.57  0.374447     0.531258  0.177329  \n",
       "17             0.59  0.177984     0.438065  0.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = scores_to_df(cv_results)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrrrrrr}\n",
      "\\toprule\n",
      " & algo & encoder & acc & macro_prec & weighted_prec & macro_recall & weighted_recall & macro_f1 & weighted_f1 & kappa \\\\\n",
      "\\midrule\n",
      "0 & Support Vector & TF-IDF & 0.590000 & 0.141500 & 0.348500 & 0.240000 & 0.590000 & 0.177984 & 0.438065 & 0.000000 \\\\\n",
      "1 & Support Vector & BERT & 0.590000 & 0.141500 & 0.348500 & 0.240000 & 0.590000 & 0.177984 & 0.438065 & 0.000000 \\\\\n",
      "2 & Support Vector & LBP & 0.590000 & 0.141500 & 0.348500 & 0.240000 & 0.590000 & 0.177984 & 0.438065 & 0.000000 \\\\\n",
      "3 & Random Forest & TF-IDF & 0.610000 & 0.234342 & 0.396079 & 0.285000 & 0.610000 & 0.240161 & 0.470538 & 0.070588 \\\\\n",
      "4 & Random Forest & BERT & 0.580000 & 0.186160 & 0.396740 & 0.247500 & 0.580000 & 0.203393 & 0.461057 & 0.028393 \\\\\n",
      "5 & Random Forest & LBP & 0.530000 & 0.238535 & 0.416617 & 0.265076 & 0.530000 & 0.241085 & 0.458170 & 0.031267 \\\\\n",
      "6 & Decision Tree & TF-IDF & 0.430000 & 0.269860 & 0.415283 & 0.288788 & 0.430000 & 0.273715 & 0.414790 & 0.016279 \\\\\n",
      "7 & Decision Tree & BERT & 0.490000 & 0.251042 & 0.480762 & 0.288697 & 0.490000 & 0.262520 & 0.480115 & 0.130162 \\\\\n",
      "8 & Decision Tree & LBP & 0.440000 & 0.250103 & 0.450608 & 0.253682 & 0.440000 & 0.233978 & 0.427401 & 0.032680 \\\\\n",
      "9 & Extra Trees & TF-IDF & 0.610000 & 0.234342 & 0.396079 & 0.285000 & 0.610000 & 0.240161 & 0.470538 & 0.070588 \\\\\n",
      "10 & Extra Trees & BERT & 0.620000 & 0.276170 & 0.470696 & 0.285833 & 0.620000 & 0.251653 & 0.502514 & 0.103766 \\\\\n",
      "11 & Extra Trees & LBP & 0.540000 & 0.237804 & 0.425727 & 0.265121 & 0.540000 & 0.240318 & 0.466100 & 0.054827 \\\\\n",
      "12 & XGBoost & TF-IDF & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
      "13 & XGBoost & BERT & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
      "14 & XGBoost & LBP & NaN & NaN & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
      "15 & MLP & TF-IDF & 0.610000 & 0.237368 & 0.403053 & 0.285000 & 0.610000 & 0.242554 & 0.476043 & 0.085423 \\\\\n",
      "16 & MLP & BERT & 0.570000 & 0.401877 & 0.528005 & 0.383864 & 0.570000 & 0.374447 & 0.531258 & 0.177329 \\\\\n",
      "17 & MLP & LBP & 0.590000 & 0.141500 & 0.348500 & 0.240000 & 0.590000 & 0.177984 & 0.438065 & 0.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cv_results_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
